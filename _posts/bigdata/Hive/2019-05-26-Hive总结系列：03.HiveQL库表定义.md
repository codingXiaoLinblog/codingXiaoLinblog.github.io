---
layout: post
title:  "Hive总结系列：03.HiveQL库表定义"
date:   2019-05-26 11:34:30
categories: Hive
tags: Hive
author: wql
---

* content
{:toc}
HiveQL是Hive查询语言,和关系型数据库所使用的SQL方言一样。但不完全遵守ANSI SQL标准。HiveQL和MySQL最接近。但还是有很大差异。本篇文章主要总结Hive库表的定义。




#  1.Hive数据库
## 1.1. 创建数据库
```sql
CREATE DATABASE IF NOT EXISTS simple location '/data/hive/dw_sms.db/sms_send_record';
```
Hive为每个数据库创建一个目录,数据库中的表将会以这个数据库目录的子目录形式存储。有一个例外就是default数据库中的表。因为这个数据库本身没有自己的目录。数据库所在的目录位于属性hive.metastore.warehouse.dir所指定的顶层目录之后。假若用户使用的这个配置项的默认配置,也就是/user/hive/warehouse,那么当我们创建数据库simple时,Hive将会对应地创建一个目录为/user/hive/warehouse/simple.db。这里请注意,数据库的文件目录名是以.db结尾的。

## 1.2.查看数据库
```sql
SHOW DATABASES;
SHOW DATABASES LIKE 'sim.*';
DESCRIBE DATABASE simple;
```
## 1.3.删除数据库
```sql

DROP DATABASE IF EXISTS simple; === DROP DATABASE IF EXISTS simple RESTRICT;
--- 若使用的是RESTRICT这个关键字,而不是CASCADE这个关键字的话,那么就和默认情况一样。
DROP DATABASE IF EXISTS simple CASCADE;
```
默认情况下Hive是不允许用户删除一个包含有表的数据仓库。要么用户先删除库中的表,然后再删数据库。要么在删除命令的最后面加上关键字CASCADE，这样Hive先自行删除数据库中的表。

## 1.4.修改数据库
```sql
ALTER DATABASE simple SET DBPROPERTIES ('edited-by'='Join');
```
使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值,来描述数据库的属性信息。数据库的其他元数据信息是不可更改的,包括数据库名和数据库所在的目录位置。


#  2. Hive创建表

## 2.1.创建表的几种方式
### 第一种（create）

```sql
create table mydb.emp(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
)
PARTITIONED BY (p_date string,p_operators	string)
row format delimited fields terminated by '\001'
location '/data/hive/dw_sms.db/sms_send_record';
```


### 第二种（复制表结构）

```sql
create table emp1 like emp;
```


### 第三种（从基表中抽取出一部分构建一张新表）

```sql
create table emp2 as select * from emp limit 10;
```
### 第四种：建AVRO格式数据表
Avro（读音类似于[ævrə]）是Hadoop的一个子项目，由Hadoop的创始人Doug Cutting牵头开发。Avro是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro提供的机制使动态语言可以方便地处理Avro数据。
```sql
CREATE EXTERNAL TABLE dw_marketing.credit_card_user
PARTITIONED BY  (p_product STRING,p_date STRING)
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.avro.AvroSerDe' 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION
  'hdfs://nameservice/data/hive/dw_marketing.db/credit_card/user/'
TBLPROPERTIES (
  'avro.schema.literal'=
  '{
    "namespace": "dw.syncer.model",
    "type": "record",
    "name": "CreditCardUser",
    "fields": [
        {"name": "phone_number", "type": "string", "doc": "手机号码"},
        {"name": "applied_time", "type": "long", "doc": "时间"},
        {"name": "bank", "type": "string", "doc": "银行"},
        {"name": "uid", "type": ["null", "string"], "default": null, "doc": "密文"},
        {"name": "eid", "type": ["null", "string"], "default": null, "doc": "外部密文"}
    ]
}'
);
```

## 2.2.hive管理表与外部表
### 1.管理表

```sql
create table if not exists emp_part(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
)
partitioned by(date string)
row format delimited fields terminated by '\t';
```
Hive管理表,有时也被称为内部表.因为这种表,Hive会或多或少的控制着数据项的生命周期.如:Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(如/user/hive/warehouse)所定义的目录的子目录下。         
当我们删除一个管理表时,Hive也会删除这个表中的数据.管理表不方便和其他工作共享数据。

### 2.外部表

```sql
create external table if not exists emp_part(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
)
partitioned by(date string)
row format delimited fields terminated by '\t';
```


```properties
管理表与外部表的区别
外部表：
   a) 共享数据
   b) 删除表时，仅删除表的元数据，不删除对应数据。
管理表：
    a)删除表时，表的元数据和对应数据都删除。
```

## 2.3.分区表
Hive中有分区表的概念。分区表将数据以一种符合逻辑的方式进行组织。比如分层存储。

### 1.管理分区表
```sql
CREATE TABLE employees (
name STRING,
salary FLOAT,
subordinates ARRAY<STRING>,
deductions MAP<STRING, FLOAT>,
address STRUCT<street:STRING, city:STRING, state:STRING, zip:INT>
)
PARTITIONED BY (country STRING, state STRING);
```
### 2.外部分区表
```sql
CREATE EXTERNAL TABLE IF NOT EXISTS log_messages (
hms INT,
severity STRING,
server STRING,
process_id INT,
message STRING)
PARTITIONED BY (year INT, month INT, day INT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
```

### 3.分区表查询的安全策略
如果表中的数据以及分区个数非常大的话,执行一个包含所有分区的查询可能会触发一个巨大的MapReduce任务。建议的安全措施是将Hive设置为“strict”模式,这样对分区表查询WHERE子句没有加分区过滤的话,将会禁止提交这个任务.可以按照下面的语句将属性设置为“nonstrict”模式。
```sql
hive> set hive.mapred.mode=strict;

hive> SELECT e.name, e.salary FROM employees e LIMIT 100;
FAILED: Error in semantic analysis: No partition predicate found for
Alias "e" Table "employees"

hive> set hive.mapred.mode=nonstrict;

hive> SELECT e.name, e.salary FROM employees e LIMIT 100;
```

## 2.4.自定义表的存储格式
Hive默认的存储格式是文本文件格式.可以通过可选的子句STORED AS TEXTFILE显式指定.同时用户可以在创建表的时指定各种各样的分隔符.
```sql
CREATE TABLE employees (
name STRING,
salary FLOAT,
subordinates ARRAY<STRING>,
deductions MAP<STRING, FLOAT>,
address STRUCT<street:STRING, city:STRING, state:STRING, zip:INT>
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\001'
COLLECTION ITEMS TERMINATED BY '\002'
MAP KEYS TERMINATED BY '\003'
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;
```
使用TEXTFILE意味着，每一行被认为是一个单独的记录.可以使用SEQUENCEFILE和RCFILE两种文件格式来替换TEXTFILE.这两种文件格式都是使用二进制编码和压缩来优化磁盘空间及I/O带宽性能的。

1. 记录编码是通过一个input format对象来控制的。Hive默认使用了一个名为org.apache.hadoop.mapred.TextInputFormat的java类.           
2. 记录的解析是由序列化/反序列化(SerDe)来控制的，对于TEXTFILEHive所使用的SerDe是org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDejava类.          
3. Hive使用一个叫做output format的对象将查询输出写入到文件中或者输出到控制台.对于TEXTFILE Hive所使用的输出类为org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

可以使用第三方的输入输出格式及SerDe，允许用户自定义Hive本身不支持的其他文件格式
```sql
CREATE TABLE kst
PARTITIONED BY (ds string)
ROW FORMAT SERDE 'com.linkedin.haivvreo.AvroSerDe'
WITH SERDEPROPERTIES ('schema.url'='http://schema_provider/kst.avsc')
STORED AS
INPUTFORMAT 'com.linkedin.haivvreo.AvroContainerInputFormat'
OUTPUTFORMAT 'com.linkedin.haivvreo.AvroContainerOutputFormat';
```